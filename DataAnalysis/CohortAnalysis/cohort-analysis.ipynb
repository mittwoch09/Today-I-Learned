{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84e40923",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'legislators' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7f0fb9d55c41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'postgresql://testuser:testpass@localhost:5432/sql_analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf_01\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"legislators\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf_02\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"legislators_terms\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2777\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2779\u001b[0;31m         sql.to_sql(\n\u001b[0m\u001b[1;32m   2780\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2781\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m    599\u001b[0m         )\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m     pandas_sql.to_sql(\n\u001b[0m\u001b[1;32m    602\u001b[0m         \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   1404\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         )\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fail\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Table '{self.name}' already exists.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Table 'legislators' already exists."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "df_01 = pd.read_csv('legislators.csv')\n",
    "df_02 = pd.read_csv('legislators_terms.csv')\n",
    "\n",
    "engine = create_engine('postgresql://testuser:testpass@localhost:5432/sql_analysis')\n",
    "\n",
    "df_01.to_sql(\"legislators\", engine)\n",
    "df_02.to_sql(\"legislators_terms\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42a6afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg2\n",
    "\n",
    "con = pg2.connect(host='localhost',\n",
    "                  user='testuser',\n",
    "                  password='tespass',\n",
    "                  database='sql_analysis')\n",
    "con.autocommit = True\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c172c334",
   "metadata": {},
   "source": [
    "### Cohort Analysis\n",
    "\n",
    "A `cohort` is a group of individuals who share some characteristic of interest, described below, at the time we start observing them.\n",
    "\n",
    "`Cohort analysis` is a useful way to compare groups of entities over time. Many important behaviors take weeks, months, or years to occur or evolve, and cohort analysis is a way to understand these changes. Cohort analysis provides a framework for detecting correlations between cohort characteristics and these long-term trends, which can lead to hypotheses about the causal drivers.\n",
    "\n",
    "Cohort analysis can be used to monitor new cohorts of users or customers and assess how they compare to previous cohorts. Such monitoring can provide an early alert signal that something has gone wrong (or right) for new customers. Cohort analysis is also used to mine historical data. A/B tests are the gold standard for determin‐ing causality, but we can’t go back in time and run every test for every question about the past in which we are interested.\n",
    "\n",
    "`Cohort grouping` is often based on a start date: the customer’s first purchase or subscription date, the date a student started school, and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5743cd",
   "metadata": {},
   "source": [
    "> **Cohort or Segment?**\n",
    ">\n",
    "> A `cohort` is a group of users (or other entities) who have a common starting date and are followed over time. A `segment` is a grouping of users who share a common characteristic or set of characteristics at a point in time, regardless of their starting date. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ad71c",
   "metadata": {},
   "source": [
    "#### Types of cohort anlaysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb023f",
   "metadata": {},
   "source": [
    "**Retention**\n",
    "\n",
    "Retention is concerned with whether the cohort member has a record in the time series on a particular date, expressed as a number of periods from the starting date. This is useful in any kind of organization in which repeated actions are expected, from playing an online game to using a product or renewing a subscription, and it helps to answer questions about how sticky or engaging a product is and how many entities can be expected to appear on future dates.\n",
    "\n",
    "**Survivorship**\n",
    "\n",
    "Survivorship is concerned with how many entities remained in the data set for a certain length of time or longer, regardless of the number or frequency of actions up to that time. Survivorship is useful for answering questions about the proportion of the population that can be expected to remain—either in a positive sense by not churning or passing away, or in a negative sense by not graduating or fulfilling some requirement.\n",
    "\n",
    "**Returnship**\n",
    "\n",
    "Returnship or repeat purchase behavior is concerned with whether an action has happened more than some minimum threshold of times—often simply more than once—during a fixed window of time. This type of analysis is useful in situations in which the behavior is intermittent and unpredictable, such as in retail, where it characterizes the share of repeat purchasers in each cohort within a fixed time window.\n",
    "\n",
    "**Cumulative**\n",
    "\n",
    "Cumulative calculations are concerned with the total number or amounts measured at one or more fixed time windows, regardless of when they happened during that window. Cumulative calculations are often used in calculations of customer lifetime value (LTV or CLTV)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f673fe71",
   "metadata": {},
   "source": [
    "#### The Legislators Data Set\n",
    "\n",
    "The SQL examples in this chapter will use a data set of past and present members of the United States Congress.\n",
    "\n",
    "Congress has two chambers, the Senate (“sen” in the data set) and the House of Representatives (“rep”). Each state has two senators, and they are elected for six-year terms. Representatives are allocated to states based on population; each representative has a district that they alone represent. Representatives are elected for two-year terms.\n",
    "\n",
    "Actual terms in either chamber can be shorter in the event that the legislator dies or is elected or appointed to a higher office. Legislators accumulate power and influence via leadership positions the longer they are in office, and thus standing for re-election is common. \n",
    "\n",
    "Finally, a legislator may belong to a political party, or they may be an “independent.” In the modern era, the vast majority of legislators are Democrats or Republicans, and the rivalry between the two parties is well known."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45188149",
   "metadata": {},
   "source": [
    "#### Retention\n",
    "\n",
    "Retention analysis uses the count of entities or sum of money or actions present in the data set for each period from the starting date, and it normalizes by dividing this number by the count or sum of entities, money, or actions in the first time period. The result is expressed as a percentage, and retention in the starting period is always 100%. Over time, retention based on counts generally declines and can never exceed 100%, whereas money- or action-based retention, while often declining, can increase and be greater than 100% in a time period. Retention analysis output is typically displayed in either table or graph form, which is referred to as a retention curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23dcd40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_bioguide</th>\n",
       "      <th>first_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A000118</td>\n",
       "      <td>1975-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P000281</td>\n",
       "      <td>1933-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K000039</td>\n",
       "      <td>1933-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A000306</td>\n",
       "      <td>1907-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O000095</td>\n",
       "      <td>1949-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12513</th>\n",
       "      <td>G000331</td>\n",
       "      <td>1949-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12514</th>\n",
       "      <td>M000103</td>\n",
       "      <td>1867-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12515</th>\n",
       "      <td>B000255</td>\n",
       "      <td>1821-12-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12516</th>\n",
       "      <td>L000152</td>\n",
       "      <td>1891-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12517</th>\n",
       "      <td>S000687</td>\n",
       "      <td>1895-12-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12518 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_bioguide  first_term\n",
       "0         A000118  1975-01-14\n",
       "1         P000281  1933-03-09\n",
       "2         K000039  1933-03-09\n",
       "3         A000306  1907-12-02\n",
       "4         O000095  1949-01-03\n",
       "...           ...         ...\n",
       "12513     G000331  1949-01-03\n",
       "12514     M000103  1867-03-04\n",
       "12515     B000255  1821-12-03\n",
       "12516     L000152  1891-12-07\n",
       "12517     S000687  1895-12-02\n",
       "\n",
       "[12518 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_01 = \"\"\"\n",
    "        SELECT id_bioguide\n",
    "            ,min(term_start) as first_term\n",
    "        FROM legislators_terms \n",
    "        GROUP BY 1\n",
    "        \"\"\"\n",
    "\n",
    "sql_01 = pd.read_sql(query_01, con)\n",
    "sql_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b2c6423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periods</th>\n",
       "      <th>cohort_retained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   periods  cohort_retained\n",
       "0      0.0            12518\n",
       "1      1.0             3600\n",
       "2      2.0             3619\n",
       "3      3.0             1831\n",
       "4      4.0             3210"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_02 = \"\"\"\n",
    "        SELECT date_part('year', age(b.term_start, a.first_term)) as periods\n",
    "            ,count(distinct a.id_bioguide) as cohort_retained\n",
    "        FROM\n",
    "        (\n",
    "                SELECT id_bioguide\n",
    "                ,min(term_start) as first_term\n",
    "                FROM legislators_terms \n",
    "                GROUP BY 1\n",
    "        ) a\n",
    "        JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n",
    "        GROUP BY 1\n",
    "        \"\"\"\n",
    "\n",
    "sql_02 = pd.read_sql(query_02, con)\n",
    "sql_02.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f2a1039",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\n        SELECT period\n            ,first_value(cohort_retained) over (order by period) as cohort_size\n            ,cohort_retained\n            ,cohort_retained * 1.0 / first_value(cohort_retained) over (order by period) as pct_retained\n        FROM\n        (\n            SELECT date_part('year',age(b.term_start,a.first_term)) as period\n            ,count(distinct a.id_bioguide) as cohort_retained\n            FROM\n            (\n                    SELECT id_bioguide\n                    ,min(term_start) as first_term\n                    FROM legislators_terms \n                    GROUP BY 1\n            ) a\n            JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n            GROUP BY 1\n        )\n        ': subquery in FROM must have an alias\nLINE 7:         (\n                ^\nHINT:  For example, FROM (SELECT ...) [AS] foo.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------\u001b[0m",
      "\u001b[0;31mSyntaxError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1724\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1725\u001b[0;31m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1726\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSyntaxError\u001b[0m: subquery in FROM must have an alias\nLINE 7:         (\n                ^\nHINT:  For example, FROM (SELECT ...) [AS] foo.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-efc1b928c25b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \"\"\"\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0msql_03\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0msql_03\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandas_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSQLiteDatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1771\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1772\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Execution failed on sql '{args[0]}': {exc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1737\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\n        SELECT period\n            ,first_value(cohort_retained) over (order by period) as cohort_size\n            ,cohort_retained\n            ,cohort_retained * 1.0 / first_value(cohort_retained) over (order by period) as pct_retained\n        FROM\n        (\n            SELECT date_part('year',age(b.term_start,a.first_term)) as period\n            ,count(distinct a.id_bioguide) as cohort_retained\n            FROM\n            (\n                    SELECT id_bioguide\n                    ,min(term_start) as first_term\n                    FROM legislators_terms \n                    GROUP BY 1\n            ) a\n            JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n            GROUP BY 1\n        )\n        ': subquery in FROM must have an alias\nLINE 7:         (\n                ^\nHINT:  For example, FROM (SELECT ...) [AS] foo.\n"
     ]
    }
   ],
   "source": [
    "query_03 = \"\"\"\n",
    "        SELECT period\n",
    "            ,first_value(cohort_retained) over (order by period) as cohort_size\n",
    "            ,cohort_retained\n",
    "            ,cohort_retained * 1.0 / first_value(cohort_retained) over (order by period) as pct_retained\n",
    "        FROM\n",
    "        (\n",
    "            SELECT date_part('year',age(b.term_start,a.first_term)) as period\n",
    "            ,count(distinct a.id_bioguide) as cohort_retained\n",
    "            FROM\n",
    "            (\n",
    "                    SELECT id_bioguide\n",
    "                    ,min(term_start) as first_term\n",
    "                    FROM legislators_terms \n",
    "                    GROUP BY 1\n",
    "            ) a\n",
    "            JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n",
    "            GROUP BY 1\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "sql_03 = pd.read_sql(query_03, con)\n",
    "sql_03.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb49d100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_size</th>\n",
       "      <th>yr0</th>\n",
       "      <th>yr1</th>\n",
       "      <th>yr2</th>\n",
       "      <th>yr3</th>\n",
       "      <th>yr4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.284732</td>\n",
       "      <td>0.28655</td>\n",
       "      <td>0.145015</td>\n",
       "      <td>0.253973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohort_size  yr0       yr1      yr2       yr3       yr4\n",
       "0        12647  1.0  0.284732  0.28655  0.145015  0.253973"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_04 = \"\"\"\n",
    "        SELECT cohort_size\n",
    "            ,max(case when period = 0 then pct_retained end) as yr0\n",
    "            ,max(case when period = 1 then pct_retained end) as yr1\n",
    "            ,max(case when period = 2 then pct_retained end) as yr2\n",
    "            ,max(case when period = 3 then pct_retained end) as yr3\n",
    "            ,max(case when period = 4 then pct_retained end) as yr4\n",
    "        FROM\n",
    "        (\n",
    "            SELECT period\n",
    "            ,first_value(cohort_retained) over (order by period) as cohort_size\n",
    "            ,cohort_retained\n",
    "            ,cohort_retained * 1.0 / first_value(cohort_retained) over (order by period) as pct_retained\n",
    "            FROM\n",
    "            (\n",
    "                SELECT \n",
    "                date_part('year',age(b.term_start,a.first_term)) as period\n",
    "                ,count(*) as cohort_retained\n",
    "                FROM\n",
    "                (\n",
    "                        SELECT id_bioguide\n",
    "                        ,min(term_start) as first_term\n",
    "                        FROM legislators_terms \n",
    "                        GROUP BY 1\n",
    "                ) a\n",
    "                JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n",
    "                GROUP BY 1\n",
    "            ) aa\n",
    "        ) aaa\n",
    "        GROUP BY 1\n",
    "        \"\"\"\n",
    "\n",
    "sql_04 = pd.read_sql(query_04, con)\n",
    "sql_04.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53d110b",
   "metadata": {},
   "source": [
    "#### Adjusting Time Series to Increase Retention Accuracy\n",
    "\n",
    "In the legislators data set, we have a record for a term’s start date, but we are missing the notion that this “entitles” a legislator to serve for two or six years, depending on the chamber.\n",
    "\n",
    "Calculating retention using a start and end date defined in the data is the most accurate approach. For the following examples, we will consider legislators retained in a particular year if they were still in office as of the last day of the year, December 31. Prior to the Twentieth Amendment to the US Constitution, terms began on March 4, but afterward the start date moved to January 3, or to a subsequent weekday if the third falls on a weekend. Legislators can be sworn in on other days of the year due to special off-cycle elections or appointments to fill vacant seats. As a result, term_start dates cluster in January but are spread across the year. \n",
    "\n",
    "While we could pick another day, **December 31** is a strategy for normalizing around these varying start dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd7ace1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
